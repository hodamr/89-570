{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_dt_50k.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYaRDDbkXHpow9gJBWYds5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rammeshulam/89-570/blob/master/Exercise_dt_50k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbhrbnunpl1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from statistics import mean\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrnVMMtdpqS1",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "The data is taken from [UCI ML Repository](http://archive.ics.uci.edu/ml/datasets/Adult). Each row desrcibes one US citizen.\n",
        "The target (the column we would like to classify) is whether income exceeds $50K/yr. The label is in the last columns.\n",
        "\n",
        "## Target: \n",
        "*  \\>50K, <=50K. \n",
        "\n",
        "## Features:\n",
        "* age: continuous. \n",
        "* workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
        "* fnlwgt: continuous. \n",
        "* education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
        "* education-num: continuous. \n",
        "* marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
        "* occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
        "* relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
        "* race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. \n",
        "* sex: Female, Male. \n",
        "* capital-gain: continuous. \n",
        "* capital-loss: continuous. \n",
        "* hours-per-week: continuous. \n",
        "* native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7KRpvf_ppYx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qvyr1Dhs3Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = ['age',\n",
        "  'workclass',\n",
        "  'fnlwgt',\n",
        "  'education',\n",
        "  'education-num',\n",
        "  'marital-status',\n",
        "  'occupation',\n",
        "  'relationship',\n",
        "  'race',\n",
        "  'sex',\n",
        "  'capital-gain',\n",
        "  'capital-loss',\n",
        "  'hours-per-week',\n",
        "  'native-country',\n",
        "  'target']\n",
        "data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "data_raw = pd.read_csv(data_url,names=cols, converters = {'target' : lambda s: s.strip()})\n",
        "data_raw.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpK6_FgFwG4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_raw.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM6Dwp31t1sP",
        "colab_type": "text"
      },
      "source": [
        "## Clean data, fill na etc'\n",
        "This is out of the scope of this assignment. Assume the data is clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNpHiQpNwHz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(25, 15))\n",
        "cols = 5\n",
        "rows = np.ceil(float(data_raw.shape[1]) / cols)\n",
        "for i, column in enumerate(data_raw.columns):\n",
        "    ax = fig.add_subplot(rows, cols, i + 1)\n",
        "    ax.set_title(column)\n",
        "    if data_raw.dtypes[column] == np.object:\n",
        "        data_raw[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
        "    else:\n",
        "        data_raw[column].hist(axes=ax)\n",
        "        plt.xticks(rotation=\"vertical\")\n",
        "plt.subplots_adjust(hspace=0.7, wspace=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKpyPeJ_zLEO",
        "colab_type": "text"
      },
      "source": [
        "# Prepare data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQgF1-H3m6Oa",
        "colab_type": "text"
      },
      "source": [
        "## Convert target to 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K7piYGVzrPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( f\"values before conversion:\\n{data_raw.target.value_counts()}\")\n",
        "\n",
        "# replace '<=50K' and '>50K' with 0 and 1 respectively\n",
        "<ADD CODE HERE>\n",
        "\n",
        "print( f\"\\nvalues after conversion:\\n{data_raw.target.value_counts()}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVN7xf59npFs",
        "colab_type": "text"
      },
      "source": [
        "## Convert categorical features\n",
        "The decision tree classifier we are about to use cannot work with categorical features. Thus, we must convert them into boolan columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPweR1F_0ZY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_raw.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dldofTDnHS9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# identify categorical vs. numerical columns:\n",
        "categorical_columns = data_raw.select_dtypes(include=object).columns.values\n",
        "numerical_columns = data_raw.select_dtypes(exclude=object).columns.values\n",
        "\n",
        "print('categorical_columns:', categorical_columns)\n",
        "print('numerical_columns:', numerical_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY7mrKrMpHyr",
        "colab_type": "text"
      },
      "source": [
        "Convert the categorical columns into dummy variables. \n",
        "For example, 'workclass' column which has the values 'Federal-gov',\t'Local-gov', 'Never-worked'... should be transformed to multiple boolean columns, one for each value: \n",
        "'workclass_ Federal-gov',\t'workclass_ Local-gov',\t'workclass_ Never-worked',.. . See [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) for reference\n",
        "\n",
        "2. concat the numerical columns to the newly created columns of the dummy variables. The new dataframe is ready for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ten3Rt4NI8m9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<ADD CODE HERE>\n",
        "print(data.head(1).T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5Dx1yqp0KsX",
        "colab_type": "text"
      },
      "source": [
        "Define X as all columns excluding target; define y as target\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb00I80OqFWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = <ADD CODE HERE>\n",
        "y = data['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgQIvLTRqWfN",
        "colab_type": "text"
      },
      "source": [
        "# Train a model\n",
        "\n",
        "## First, lets split the data to train and test data sets.\n",
        "Split the data into 90% train and 10% test data sets. For consistency, use random_state=42. see [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU3BkLg6Kk3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create X_train, X_test, y_train, y_test\n",
        "<ADD CODE HERE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkCSOcQlrFV8",
        "colab_type": "text"
      },
      "source": [
        "1. On the training set, create a decision tree classifier \n",
        "2. Use 10-fold cross-validation to calculate the performance of the model.\n",
        "\n",
        "See [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and  [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) for reference.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCVMzYWnJWqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = <ADD CODE HERE>\n",
        "\n",
        "#print score:\n",
        "<ADD CODE HERE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRxwQsq2sJVR",
        "colab_type": "text"
      },
      "source": [
        "# Tune model hyper parameters\n",
        "Lets find the optimal tree depth based on the training set data:\n",
        "1. Loop over depths from 1 to 15\n",
        "2. for each depth, create a decision-tree with max_depth=depth and calcualate the average cross_val_score (use 10-fold cross-validation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZtGszXsMYOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# returns a list of performance for each depth in depths\n",
        "def check_depths(depths, X, y):\n",
        "  <ADD CODE HERE>\n",
        "  \n",
        "depths = range(1,16)\n",
        "performance = check_depths(depths, X_train, y_train)\n",
        "best_p = max(performance)\n",
        "best_pi = performance.index(best_p)\n",
        "\n",
        "print((f\"max performance ({best_p}) achieved at depth {best_pi}\"))\n",
        "plt.plot(depths, performance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyaZvFF5tFRJ",
        "colab_type": "text"
      },
      "source": [
        "# Report performance\n",
        "For final performance report, \n",
        "1. create a decision-tree classifier with max_detph=best_pi\n",
        "2. Use all the training set to train it\n",
        "3. calculate the accuracy on the test set (use DecisionTreeClassifier.score() function). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5gIOGhQOZsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<ADD CODE HERE>"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}